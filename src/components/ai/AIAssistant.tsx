import { useState, useRef, useEffect, useCallback } from 'react';
import { motion, AnimatePresence } from 'framer-motion';
import { Send, Mic, MicOff, Image, X, Loader2, Bot, User, Leaf, Bug, WifiOff, Wifi, CloudOff, Trash2, Volume2, VolumeX, Settings } from 'lucide-react';
import { Button } from '@/components/ui/button';
import { Textarea } from '@/components/ui/textarea';
import { Card } from '@/components/ui/card';
import { Switch } from '@/components/ui/switch';
import { useToast } from '@/hooks/use-toast';
import { useLanguage } from '@/hooks/useLanguage';
import { usePlots } from '@/hooks/useFarmerData';
import { useNetworkStatus } from '@/hooks/useNetworkStatus';
import { useVoiceInput } from '@/hooks/useVoiceInput';
import { useTextToSpeech } from '@/hooks/useTextToSpeech';
import { offlineStorage } from '@/lib/offlineStorage';
import { VoiceChatButton } from './VoiceChatButton';
import { TreatmentVideoCards, type TreatmentVideo } from './TreatmentVideoCards';

interface Message {
  id: string;
  role: 'user' | 'assistant';
  content: string;
  imageUrl?: string;
  timestamp: Date;
  pending?: boolean;
  isOfflineResponse?: boolean;
  treatments?: TreatmentVideo[];
}

interface AIAssistantProps {
  initialAction?: 'chat' | 'recommend' | 'disease' | null;
}

export function AIAssistant({ initialAction = null }: AIAssistantProps) {
  const [messages, setMessages] = useState<Message[]>([]);
  const [input, setInput] = useState('');
  const [isLoading, setIsLoading] = useState(false);
  const [selectedImage, setSelectedImage] = useState<string | null>(null);
  const [isAnalyzingDisease, setIsAnalyzingDisease] = useState(false);
  const [isGettingRecommendations, setIsGettingRecommendations] = useState(false);
  const [pendingCount, setPendingCount] = useState(0);
  const [autoPlayTTS, setAutoPlayTTS] = useState(() => {
    const saved = localStorage.getItem('krishi-mitra-autoplay-tts');
    return saved === 'true';
  });
  const [showSettings, setShowSettings] = useState(false);
  const lastAssistantMessageIdRef = useRef<string | null>(null);
  const messagesEndRef = useRef<HTMLDivElement>(null);
  const fileInputRef = useRef<HTMLInputElement>(null);
  const diseaseInputRef = useRef<HTMLInputElement>(null);
  const { toast } = useToast();
  const { t, language } = useLanguage();
  const { data: plots } = usePlots();
  const { isOnline, wasOffline } = useNetworkStatus();

  // Voice input hook
  const { 
    isListening, 
    isSupported: isVoiceSupported, 
    transcript, 
    startListening, 
    stopListening 
  } = useVoiceInput({
    language,
    onResult: (text) => {
      setInput(prev => prev ? `${prev} ${text}` : text);
    },
    onError: (error) => {
      toast({
        title: "Voice Error",
        description: error,
        variant: "destructive"
      });
    }
  });

  // Text-to-speech hook
  const {
    speak,
    toggle: toggleSpeech,
    stop: stopSpeech,
    isSpeaking,
    isSupported: isTTSSupported,
    currentMessageId: speakingMessageId
  } = useTextToSpeech({
    language,
    onError: (error) => {
      toast({
        title: "Speech Error",
        description: error,
        variant: "destructive"
      });
    }
  });

  // Save auto-play preference
  useEffect(() => {
    localStorage.setItem('krishi-mitra-autoplay-tts', autoPlayTTS.toString());
  }, [autoPlayTTS]);

  // Update input with interim transcript while listening
  useEffect(() => {
    if (isListening && transcript) {
      setInput(transcript);
    }
  }, [transcript, isListening]);

  const scrollToBottom = () => {
    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
  };

  useEffect(() => {
    scrollToBottom();
  }, [messages]);

  // Load saved conversations on mount
  useEffect(() => {
    const savedMessages = offlineStorage.loadConversations();
    if (savedMessages.length > 0) {
      setMessages(savedMessages);
    }
    const pending = offlineStorage.getPendingMessages();
    setPendingCount(pending.length);
  }, []);

  // Save conversations when messages change
  useEffect(() => {
    if (messages.length > 0) {
      offlineStorage.saveConversations(messages);
    }
  }, [messages]);

  // Auto-play TTS when assistant message streaming completes
  useEffect(() => {
    if (!autoPlayTTS || !isTTSSupported) return;
    
    const lastMessage = messages[messages.length - 1];
    if (
      lastMessage?.role === 'assistant' && 
      lastMessage.content && 
      !isLoading && 
      !isAnalyzingDisease && 
      !isGettingRecommendations &&
      lastMessage.id !== lastAssistantMessageIdRef.current
    ) {
      // New completed assistant message - auto-play it
      lastAssistantMessageIdRef.current = lastMessage.id;
      speak(lastMessage.content, lastMessage.id);
    }
  }, [messages, autoPlayTTS, isTTSSupported, isLoading, isAnalyzingDisease, isGettingRecommendations, speak]);

  // Handle realtime voice chat messages
  const handleRealtimeMessage = useCallback((msg: { role: 'user' | 'assistant'; content: string }) => {
    const newMessage: Message = {
      id: crypto.randomUUID(),
      role: msg.role,
      content: msg.content,
      timestamp: new Date()
    };
    setMessages(prev => [...prev, newMessage]);
  }, []);

  // Process pending messages when back online
  useEffect(() => {
    if (isOnline && wasOffline) {
      const pending = offlineStorage.getPendingMessages();
      if (pending.length > 0) {
        toast({
          title: "Back online!",
          description: `Sending ${pending.length} queued message(s)...`,
        });
        processPendingMessages();
      }
    }
  }, [isOnline, wasOffline]);

  const processPendingMessages = async () => {
    const pending = offlineStorage.getPendingMessages();
    
    for (const pendingMsg of pending) {
      try {
        const response = await fetch(
          `${import.meta.env.VITE_SUPABASE_URL}/functions/v1/ai-farm-assistant`,
          {
            method: 'POST',
            headers: {
              'Content-Type': 'application/json',
              Authorization: `Bearer ${import.meta.env.VITE_SUPABASE_PUBLISHABLE_KEY}`,
            },
            body: JSON.stringify({
              messages: pendingMsg.messages,
              language
            }),
          }
        );

        if (response.ok) {
          // Process streaming response
          const reader = response.body?.getReader();
          const decoder = new TextDecoder();
          let assistantContent = '';
          const assistantMessageId = crypto.randomUUID();

          setMessages(prev => [...prev, {
            id: assistantMessageId,
            role: 'assistant',
            content: '',
            timestamp: new Date()
          }]);

          if (reader) {
            let textBuffer = '';
            
            while (true) {
              const { done, value } = await reader.read();
              if (done) break;

              textBuffer += decoder.decode(value, { stream: true });
              
              let newlineIndex: number;
              while ((newlineIndex = textBuffer.indexOf('\n')) !== -1) {
                let line = textBuffer.slice(0, newlineIndex);
                textBuffer = textBuffer.slice(newlineIndex + 1);
                
                if (line.endsWith('\r')) line = line.slice(0, -1);
                if (line.startsWith(':') || line.trim() === '') continue;
                if (!line.startsWith('data: ')) continue;
                
                const jsonStr = line.slice(6).trim();
                if (jsonStr === '[DONE]') break;
                
                try {
                  const parsed = JSON.parse(jsonStr);
                  const content = parsed.choices?.[0]?.delta?.content;
                  if (content) {
                    assistantContent += content;
                    setMessages(prev => prev.map(m => 
                      m.id === assistantMessageId 
                        ? { ...m, content: assistantContent }
                        : m
                    ));
                  }
                } catch {
                  // Incomplete JSON, continue
                }
              }
            }
          }

          offlineStorage.removePendingMessage(pendingMsg.id);
          setPendingCount(prev => prev - 1);
        }
      } catch (error) {
        console.error('Failed to process pending message:', error);
      }
    }
  };

  // Handle initial action
  useEffect(() => {
    if (initialAction === 'recommend' && messages.length === 0) {
      handleGetCropRecommendations();
    } else if (initialAction === 'disease' && messages.length === 0) {
      diseaseInputRef.current?.click();
    }
  }, [initialAction]);

  const handleImageUpload = (e: React.ChangeEvent<HTMLInputElement>) => {
    const file = e.target.files?.[0];
    if (file) {
      if (file.size > 5 * 1024 * 1024) {
        toast({
          title: "File too large",
          description: "Please select an image smaller than 5MB",
          variant: "destructive"
        });
        return;
      }
      
      const reader = new FileReader();
      reader.onload = () => {
        setSelectedImage(reader.result as string);
      };
      reader.readAsDataURL(file);
    }
  };

  const handleDiseaseImageUpload = async (e: React.ChangeEvent<HTMLInputElement>) => {
    const file = e.target.files?.[0];
    if (!file) return;

    if (file.size > 5 * 1024 * 1024) {
      toast({
        title: "File too large",
        description: "Please select an image smaller than 5MB",
        variant: "destructive"
      });
      return;
    }

    const reader = new FileReader();
    reader.onload = async () => {
      const imageUrl = reader.result as string;
      
      // Add user message with image
      const userMessage: Message = {
        id: crypto.randomUUID(),
        role: 'user',
        content: 'Please analyze this crop image for diseases or pests.',
        imageUrl,
        timestamp: new Date()
      };
      setMessages(prev => [...prev, userMessage]);

      if (!isOnline) {
        // Offline response for disease detection
        const offlineMessage: Message = {
          id: crypto.randomUUID(),
          role: 'assistant',
          content: `üì¥ **Offline Mode - Image Saved**

I've saved your crop image. I'll analyze it when you're back online.

**While waiting, check for these common signs:**

üçÇ **Yellow/Brown Spots** ‚Üí Possible fungal infection
üêõ **Holes in Leaves** ‚Üí Pest damage
ü•Ä **Wilting** ‚Üí Root issues or water stress
‚ö™ **White Powder** ‚Üí Powdery mildew

üí° *The image will be analyzed automatically when connectivity is restored.*`,
          timestamp: new Date(),
          isOfflineResponse: true
        };
        setMessages(prev => [...prev, offlineMessage]);
        
        // Queue for later processing
        offlineStorage.queuePendingMessage({
          id: crypto.randomUUID(),
          messages: [{
            role: 'user',
            content: 'Please analyze this crop image for diseases or pests.',
            imageUrl
          }],
          timestamp: new Date()
        });
        setPendingCount(prev => prev + 1);
        
        toast({
          title: "Image saved offline",
          description: "Will analyze when you're back online",
        });
        return;
      }

      setIsAnalyzingDisease(true);

      try {
        const response = await fetch(
          `${import.meta.env.VITE_SUPABASE_URL}/functions/v1/analyze-crop-disease`,
          {
            method: 'POST',
            headers: {
              'Content-Type': 'application/json',
              Authorization: `Bearer ${import.meta.env.VITE_SUPABASE_PUBLISHABLE_KEY}`,
            },
            body: JSON.stringify({
              imageUrl,
              language,
              cropType: plots?.[0]?.crop_type || undefined
            }),
          }
        );

        if (!response.ok) {
          throw new Error('Failed to analyze image');
        }

        const analysis = await response.json();
        
        // Format the response
        let responseContent = '';
        if (analysis.isHealthy) {
          responseContent = `‚úÖ **Good news! Your crop looks healthy.**\n\nConfidence: ${Math.round((analysis.confidence || 0.8) * 100)}%\n\nKeep up the good farming practices!`;
        } else {
          responseContent = `üîç **Disease Detection Result**\n\n`;
          responseContent += `**Detected Issue:** ${analysis.detectedIssue || 'Unknown'}\n`;
          responseContent += `**Confidence:** ${Math.round((analysis.confidence || 0.7) * 100)}%\n`;
          responseContent += `**Severity:** ${analysis.severity || 'Unknown'}\n\n`;
          
          if (analysis.symptoms?.length > 0) {
            responseContent += `**Symptoms:**\n${analysis.symptoms.map((s: string) => `‚Ä¢ ${s}`).join('\n')}\n\n`;
          }
          
          if (analysis.immediateActions?.length > 0) {
            responseContent += `**Immediate Actions:**\n`;
            analysis.immediateActions.forEach((action: any) => {
              responseContent += `‚Ä¢ ${action.action}\n`;
            });
            responseContent += '\n';
          }
          
          if (analysis.organicTreatment) {
            responseContent += `**üåø Organic Treatment:**\n`;
            responseContent += `${analysis.organicTreatment.name}\n`;
            responseContent += `Preparation: ${analysis.organicTreatment.preparation}\n`;
            responseContent += `Application: ${analysis.organicTreatment.application}\n\n`;
          }
          
          if (analysis.chemicalTreatment) {
            responseContent += `**üíä Chemical Treatment:**\n`;
            responseContent += `${analysis.chemicalTreatment.name}\n`;
            responseContent += `Dosage: ${analysis.chemicalTreatment.dosage}\n\n`;
          }
          
          if (analysis.preventiveMeasures?.length > 0) {
            responseContent += `**Prevention Tips:**\n${analysis.preventiveMeasures.map((p: string) => `‚Ä¢ ${p}`).join('\n')}\n\n`;
          }
          
          if (analysis.whenToSeekHelp) {
            responseContent += `‚ö†Ô∏è **When to consult expert:** ${analysis.whenToSeekHelp}`;
          }
        }

        const assistantMessage: Message = {
          id: crypto.randomUUID(),
          role: 'assistant',
          content: responseContent,
          timestamp: new Date()
        };
        setMessages(prev => [...prev, assistantMessage]);
      } catch (error) {
        toast({
          title: 'Analysis Failed',
          description: error instanceof Error ? error.message : 'Could not analyze image',
          variant: 'destructive'
        });
      } finally {
        setIsAnalyzingDisease(false);
        if (diseaseInputRef.current) {
          diseaseInputRef.current.value = '';
        }
      }
    };
    reader.readAsDataURL(file);
  };

  const handleGetCropRecommendations = async () => {
    if (!plots || plots.length === 0) {
      toast({
        title: "No plots found",
        description: "Please add a plot first to get personalized recommendations",
        variant: "destructive"
      });
      return;
    }

    const plot = plots[0];
    
    const userMessage: Message = {
      id: crypto.randomUUID(),
      role: 'user',
      content: `Get crop recommendations for my ${plot.crop_type} field (${plot.area_hectares || 'unknown'} hectares) in ${plot.village || plot.district || plot.state || 'my area'}.`,
      timestamp: new Date()
    };
    setMessages(prev => [...prev, userMessage]);

    if (!isOnline) {
      // Provide offline crop recommendations
      const offlineResponse = offlineStorage.getOfflineResponse('crop');
      const offlineMessage: Message = {
        id: crypto.randomUUID(),
        role: 'assistant',
        content: offlineResponse,
        timestamp: new Date(),
        isOfflineResponse: true
      };
      setMessages(prev => [...prev, offlineMessage]);
      return;
    }

    setIsGettingRecommendations(true);

    try {
      // Fetch weather data if plot has coordinates
      let weatherData = {
        temperature: 28,
        humidity: 65,
        rainfall: 100
      };

      if (plot.latitude && plot.longitude) {
        try {
          const weatherResponse = await fetch(
            `${import.meta.env.VITE_SUPABASE_URL}/functions/v1/fetch-weather`,
            {
              method: 'POST',
              headers: {
                'Content-Type': 'application/json',
                Authorization: `Bearer ${import.meta.env.VITE_SUPABASE_PUBLISHABLE_KEY}`,
              },
              body: JSON.stringify({
                latitude: plot.latitude,
                longitude: plot.longitude
              }),
            }
          );
          if (weatherResponse.ok) {
            const weather = await weatherResponse.json();
            weatherData = {
              temperature: weather.temperature || 28,
              humidity: weather.humidity || 65,
              rainfall: weather.rainfall || 100
            };
          }
        } catch (e) {
          console.log('Could not fetch weather, using defaults');
        }
      }

      const response = await fetch(
        `${import.meta.env.VITE_SUPABASE_URL}/functions/v1/crop-recommendation`,
        {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            Authorization: `Bearer ${import.meta.env.VITE_SUPABASE_PUBLISHABLE_KEY}`,
          },
          body: JSON.stringify({
            soilData: {
              ph: 6.5,
              moisture: 45,
              nitrogen: 280,
              phosphorus: 45,
              potassium: 200,
              soilType: 'Loamy'
            },
            weatherData,
            plotInfo: {
              latitude: plot.latitude || 20.5937,
              longitude: plot.longitude || 78.9629,
              areaHectares: plot.area_hectares || 2,
              state: plot.state || 'Nepal',
              district: plot.district || '',
              season: plot.season || 'Kharif',
              previousCrop: plot.crop_type
            },
            language
          }),
        }
      );

      if (!response.ok) {
        throw new Error('Failed to get recommendations');
      }

      const data = await response.json();
      
      let responseContent = `üåæ **Crop Recommendations for Your Field**\n\n`;
      responseContent += `**Soil Health Score:** ${Math.round((data.soilHealthScore || 0.7) * 100)}%\n`;
      responseContent += `**Sustainability Score:** ${Math.round((data.sustainabilityScore || 0.7) * 100)}%\n\n`;
      
      if (data.recommendations && data.recommendations.length > 0) {
        responseContent += `**Top Recommended Crops:**\n\n`;
        data.recommendations.slice(0, 3).forEach((rec: any, index: number) => {
          const medal = index === 0 ? 'ü•á' : index === 1 ? 'ü•à' : 'ü•â';
          responseContent += `${medal} **${rec.crop}**\n`;
          responseContent += `   Suitability: ${Math.round((rec.suitabilityScore || 0.8) * 100)}%\n`;
          responseContent += `   Expected Yield: ${rec.expectedYieldPerHectare || 'N/A'}\n`;
          responseContent += `   Profit Estimate: ${rec.estimatedProfitPerHectare || 'N/A'}\n`;
          responseContent += `   Water Needs: ${rec.waterRequirement || 'Medium'}\n\n`;
        });
      }

      if (data.soilImprovementTips && data.soilImprovementTips.length > 0) {
        responseContent += `**üí° Soil Improvement Tips:**\n`;
        data.soilImprovementTips.forEach((tip: string) => {
          responseContent += `‚Ä¢ ${tip}\n`;
        });
        responseContent += '\n';
      }

      if (data.reasoning) {
        responseContent += `**Analysis:** ${data.reasoning}`;
      }

      const assistantMessage: Message = {
        id: crypto.randomUUID(),
        role: 'assistant',
        content: responseContent,
        timestamp: new Date()
      };
      setMessages(prev => [...prev, assistantMessage]);
    } catch (error) {
      toast({
        title: 'Recommendation Failed',
        description: error instanceof Error ? error.message : 'Could not get recommendations',
        variant: 'destructive'
      });
    } finally {
      setIsGettingRecommendations(false);
    }
  };

  const sendMessage = async () => {
    if (!input.trim() && !selectedImage) return;

    const userMessage: Message = {
      id: crypto.randomUUID(),
      role: 'user',
      content: input || (selectedImage ? 'Please analyze this image' : ''),
      imageUrl: selectedImage || undefined,
      timestamp: new Date()
    };

    setMessages(prev => [...prev, userMessage]);
    const currentInput = input;
    setInput('');
    setSelectedImage(null);

    // Handle offline mode
    if (!isOnline) {
      const offlineResponse = offlineStorage.getOfflineResponse(currentInput);
      const offlineMessage: Message = {
        id: crypto.randomUUID(),
        role: 'assistant',
        content: offlineResponse,
        timestamp: new Date(),
        isOfflineResponse: true
      };
      setMessages(prev => [...prev, offlineMessage]);
      
      // Queue the message for when we're back online (only if it needs AI processing)
      if (selectedImage || !offlineResponse.includes('Offline Mode')) {
        offlineStorage.queuePendingMessage({
          id: crypto.randomUUID(),
          messages: [{
            role: 'user',
            content: currentInput,
            imageUrl: selectedImage || undefined
          }],
          timestamp: new Date()
        });
        setPendingCount(prev => prev + 1);
      }
      return;
    }

    setIsLoading(true);

    try {
      const apiMessages = messages.map(m => ({
        role: m.role,
        content: m.content,
        imageUrl: m.imageUrl
      }));
      
      apiMessages.push({
        role: 'user',
        content: userMessage.content,
        imageUrl: userMessage.imageUrl
      });

      const response = await fetch(
        `${import.meta.env.VITE_SUPABASE_URL}/functions/v1/ai-farm-assistant`,
        {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            Authorization: `Bearer ${import.meta.env.VITE_SUPABASE_PUBLISHABLE_KEY}`,
          },
          body: JSON.stringify({
            messages: apiMessages,
            language
          }),
        }
      );

      if (!response.ok) {
        const errorData = await response.json();
        throw new Error(errorData.error || 'Failed to get response');
      }

      // Handle streaming response
      const reader = response.body?.getReader();
      const decoder = new TextDecoder();
      let assistantContent = '';
      const assistantMessageId = crypto.randomUUID();

      // Add empty assistant message
      setMessages(prev => [...prev, {
        id: assistantMessageId,
        role: 'assistant',
        content: '',
        timestamp: new Date()
      }]);

      if (reader) {
        let textBuffer = '';
        let receivedTreatments: TreatmentVideo[] = [];
        
        while (true) {
          const { done, value } = await reader.read();
          if (done) break;

          textBuffer += decoder.decode(value, { stream: true });
          
          let newlineIndex: number;
          while ((newlineIndex = textBuffer.indexOf('\n')) !== -1) {
            let line = textBuffer.slice(0, newlineIndex);
            textBuffer = textBuffer.slice(newlineIndex + 1);
            
            if (line.endsWith('\r')) line = line.slice(0, -1);
            if (line.startsWith(':') || line.trim() === '') continue;
            if (!line.startsWith('data: ')) continue;
            
            const jsonStr = line.slice(6).trim();
            if (jsonStr === '[DONE]') break;
            
            try {
              const parsed = JSON.parse(jsonStr);
              
              // Check if this is a treatments object
              if (parsed.treatments && Array.isArray(parsed.treatments)) {
                receivedTreatments = parsed.treatments;
                console.log('[AI] Received treatments:', receivedTreatments.length);
                // Update the message with treatments
                setMessages(prev => prev.map(m => 
                  m.id === assistantMessageId 
                    ? { ...m, treatments: receivedTreatments }
                    : m
                ));
                continue;
              }
              
              const content = parsed.choices?.[0]?.delta?.content;
              if (content) {
                assistantContent += content;
                setMessages(prev => prev.map(m => 
                  m.id === assistantMessageId 
                    ? { ...m, content: assistantContent, treatments: receivedTreatments }
                    : m
                ));
              }
            } catch {
              // Incomplete JSON, continue
            }
          }
        }
      }
    } catch (error) {
      toast({
        title: t('error'),
        description: error instanceof Error ? error.message : 'Failed to get response',
        variant: 'destructive'
      });
    } finally {
      setIsLoading(false);
    }
  };

  const handleKeyPress = (e: React.KeyboardEvent) => {
    if (e.key === 'Enter' && !e.shiftKey) {
      e.preventDefault();
      sendMessage();
    }
  };

  const toggleRecording = () => {
    if (!isVoiceSupported) {
      toast({
        title: language === 'ne' ? "‡§Ü‡§µ‡§æ‡§ú ‡§∏‡§Æ‡§∞‡•ç‡§•‡§ø‡§§ ‡§õ‡•à‡§®" : "Voice not supported",
        description: language === 'ne' 
          ? "‡§§‡§™‡§æ‡§à‡§Ç‡§ï‡•ã ‡§¨‡•ç‡§∞‡§æ‡§â‡§ú‡§∞‡§≤‡•á ‡§Ü‡§µ‡§æ‡§ú ‡§á‡§®‡§™‡•Å‡§ü ‡§∏‡§Æ‡§∞‡•ç‡§•‡§® ‡§ó‡§∞‡•ç‡§¶‡•à‡§®‡•§ Chrome ‡§µ‡§æ Edge ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§ó‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç‡•§"
          : "Your browser doesn't support voice input. Try Chrome or Edge.",
        variant: "destructive"
      });
      return;
    }

    if (isListening) {
      stopListening();
      if (transcript) {
        toast({
          title: language === 'ne' ? "‚úÖ ‡§Ü‡§µ‡§æ‡§ú ‡§∞‡•á‡§ï‡§∞‡•ç‡§° ‡§≠‡§Ø‡•ã" : "‚úÖ Voice recorded",
          description: language === 'ne' ? "‡§§‡§™‡§æ‡§à‡§Ç‡§ï‡•ã ‡§∏‡§®‡•ç‡§¶‡•á‡§∂ ‡§§‡§Ø‡§æ‡§∞ ‡§õ‡•§" : "Your message is ready.",
        });
      }
    } else {
      startListening();
      toast({
        title: language === 'ne' ? "üé§ ‡§∏‡•Å‡§®‡§ø‡§∞‡§π‡•á‡§ï‡•ã ‡§õ..." : "üé§ Listening...",
        description: language === 'ne' 
          ? "‡§®‡•á‡§™‡§æ‡§≤‡•Ä‡§Æ‡§æ ‡§¨‡•ã‡§≤‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç‡•§ ‡§¨‡•ã‡§≤‡•ç‡§® ‡§∏‡§ï‡•á‡§™‡§õ‡§ø ‡§Æ‡§æ‡§á‡§ï ‡§•‡§ø‡§ö‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç‡•§"
          : "Speak in your language. Tap mic when done.",
      });
    }
  };

  const clearChat = () => {
    stopSpeech(); // Stop any playing speech
    setMessages([]);
    offlineStorage.clearConversations();
    toast({
      title: "Chat cleared",
      description: "All messages have been deleted",
    });
  };

  const isProcessing = isLoading || isAnalyzingDisease || isGettingRecommendations;

  return (
    <div className="flex flex-col h-full bg-background min-h-0">
      {/* Offline Status Banner */}
      {!isOnline && (
        <motion.div
          initial={{ opacity: 0, y: -20 }}
          animate={{ opacity: 1, y: 0 }}
          className="bg-warning/20 border-b border-warning/30 px-3 sm:px-4 py-2 flex items-center gap-2 flex-shrink-0"
        >
          <WifiOff className="w-4 h-4 text-warning flex-shrink-0" />
          <span className="text-xs sm:text-sm text-warning font-medium">
            {language === 'ne' ? '‡§Ö‡§´‡§≤‡§æ‡§á‡§® ‡§Æ‡•ã‡§°' : 'Offline Mode'}
          </span>
          {pendingCount > 0 && (
            <span className="text-xs bg-warning/30 px-2 py-0.5 rounded-full">
              {pendingCount} {language === 'ne' ? '‡§™‡•á‡§®‡•ç‡§°‡§ø‡§ô' : 'pending'}
            </span>
          )}
        </motion.div>
      )}

      {/* Back Online Banner */}
      {isOnline && wasOffline && pendingCount > 0 && (
        <motion.div
          initial={{ opacity: 0, y: -20 }}
          animate={{ opacity: 1, y: 0 }}
          className="bg-success/20 border-b border-success/30 px-3 sm:px-4 py-2 flex items-center gap-2 flex-shrink-0"
        >
          <Wifi className="w-4 h-4 text-success flex-shrink-0" />
          <span className="text-xs sm:text-sm text-success font-medium">
            {language === 'ne' ? '‡§Ö‡§®‡§≤‡§æ‡§á‡§® ‡§≠‡§Ø‡•ã! ‡§∏‡§ø‡§Ç‡§ï ‡§π‡•Å‡§Å‡§¶‡•à‡§õ...' : 'Back online! Syncing...'}
          </span>
        </motion.div>
      )}

      {/* Messages */}
      <div className="flex-1 overflow-y-auto p-3 sm:p-4 space-y-3 sm:space-y-4 min-h-0">
        {messages.length === 0 && (
          <div className="flex flex-col items-center justify-center h-full text-center p-4 sm:p-6">
            <div className="w-12 h-12 sm:w-16 sm:h-16 rounded-full bg-gradient-to-br from-primary/20 to-accent/20 flex items-center justify-center mb-3 sm:mb-4">
              <Bot className="w-6 h-6 sm:w-8 sm:h-8 text-primary" />
            </div>
            <h4 className="font-semibold text-base sm:text-lg mb-1 sm:mb-2">
              {language === 'ne' ? '‡§®‡§Æ‡§∏‡•ç‡§ï‡§æ‡§∞! ‡§Æ ‡§ï‡•É‡§∑‡§ø ‡§Æ‡§ø‡§§‡•ç‡§∞ ‡§π‡•Å‡§Å üôè' : 'Namaste! I am Krishi Mitra üôè'}
            </h4>
            <p className="text-xs sm:text-sm text-muted-foreground max-w-xs mb-4 sm:mb-6">
              {isOnline 
                ? (language === 'ne' 
                    ? '‡§¨‡§æ‡§≤‡•Ä ‡§´‡•ã‡§ü‡•ã ‡§Ö‡§™‡§≤‡•ã‡§° ‡§ó‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç, ‡§∞‡•ã‡§ó ‡§™‡§§‡•ç‡§§‡§æ ‡§≤‡§ó‡§æ‡§â‡§®‡•Å‡§π‡•ã‡§∏‡•ç, ‡§µ‡§æ ‡§ñ‡•á‡§§‡•Ä‡§ï‡•ã ‡§¨‡§æ‡§∞‡•á‡§Æ‡§æ ‡§∏‡•ã‡§ß‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç‡•§'
                    : 'Upload crop photos for disease detection, get recommendations, or ask farming questions.')
                : (language === 'ne'
                    ? '‡§§‡§™‡§æ‡§à‡§Ç ‡§Ö‡§´‡§≤‡§æ‡§á‡§® ‡§π‡•Å‡§®‡•Å‡§π‡•Å‡§®‡•ç‡§õ‡•§ ‡§Ü‡§ß‡§æ‡§∞‡§≠‡•Ç‡§§ ‡§∏‡•Å‡§ù‡§æ‡§µ ‡§â‡§™‡§≤‡§¨‡•ç‡§ß ‡§õ‡•§'
                    : 'You\'re offline. Basic tips are available.')}
            </p>
            
            {/* Quick Action Buttons */}
            <div className="grid grid-cols-1 sm:grid-cols-2 gap-2 sm:gap-3 w-full max-w-sm mb-4">
              <Button
                variant="outline"
                className="flex items-center gap-2 h-auto py-2 sm:py-3 justify-start text-left"
                onClick={handleGetCropRecommendations}
                disabled={isProcessing}
              >
                <div className="w-7 h-7 sm:w-8 sm:h-8 rounded-full bg-primary/10 flex items-center justify-center flex-shrink-0">
                  <Leaf className="w-3.5 h-3.5 sm:w-4 sm:h-4 text-primary" />
                </div>
                <div className="min-w-0">
                  <div className="font-medium text-xs sm:text-sm truncate">
                    {language === 'ne' ? '‡§¨‡§æ‡§≤‡•Ä ‡§∏‡§ø‡§´‡§æ‡§∞‡§ø‡§∏' : 'Crop Recommendations'}
                  </div>
                  <div className="text-[10px] sm:text-xs text-muted-foreground truncate">
                    {isOnline 
                      ? (language === 'ne' ? '‡§§‡§™‡§æ‡§à‡§Ç‡§ï‡•ã ‡§ñ‡•á‡§§‡§ï‡§æ ‡§≤‡§æ‡§ó‡§ø' : 'Based on your field')
                      : (language === 'ne' ? '‡§∏‡§æ‡§Æ‡§æ‡§®‡•ç‡§Ø ‡§∏‡•Å‡§ù‡§æ‡§µ' : 'General tips')}
                  </div>
                </div>
              </Button>
              <Button
                variant="outline"
                className="flex items-center gap-2 h-auto py-2 sm:py-3 justify-start text-left"
                onClick={() => diseaseInputRef.current?.click()}
                disabled={isProcessing}
              >
                <div className="w-7 h-7 sm:w-8 sm:h-8 rounded-full bg-destructive/10 flex items-center justify-center flex-shrink-0">
                  <Bug className="w-3.5 h-3.5 sm:w-4 sm:h-4 text-destructive" />
                </div>
                <div className="min-w-0">
                  <div className="font-medium text-xs sm:text-sm truncate">
                    {language === 'ne' ? '‡§∞‡•ã‡§ó ‡§ú‡§æ‡§Å‡§ö ‡§ó‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç' : 'Scan for Disease'}
                  </div>
                  <div className="text-[10px] sm:text-xs text-muted-foreground truncate">
                    {isOnline 
                      ? (language === 'ne' ? '‡§´‡•ã‡§ü‡•ã ‡§Ö‡§™‡§≤‡•ã‡§° ‡§ó‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç' : 'Upload crop photo')
                      : (language === 'ne' ? '‡§™‡§õ‡§ø ‡§ú‡§æ‡§Å‡§ö ‡§π‡•Å‡§®‡•á‡§õ' : 'Save for later')}
                  </div>
                </div>
              </Button>
            </div>

            {/* Voice Chat & Settings for empty state */}
            <div className="flex items-center justify-center gap-3 mb-4">
              {isOnline && (
                <VoiceChatButton onMessage={handleRealtimeMessage} />
              )}
              <div className="flex items-center gap-2 text-xs">
                <Volume2 className="w-3.5 h-3.5 text-muted-foreground" />
                <span className="text-muted-foreground">
                  {language === 'ne' ? '‡§∏‡•ç‡§µ‡§§: ‡§Ü‡§µ‡§æ‡§ú' : 'Auto-play'}
                </span>
                <Switch
                  checked={autoPlayTTS}
                  onCheckedChange={setAutoPlayTTS}
                  disabled={!isTTSSupported}
                  className="scale-75"
                />
              </div>
            </div>

            <div className="flex flex-wrap gap-1.5 sm:gap-2 justify-center">
              {[
                language === 'ne' ? '‡§Æ‡•á‡§∞‡•ã ‡§¨‡§æ‡§≤‡•Ä‡§Æ‡§æ ‡§™‡§π‡•á‡§Ç‡§≤‡•ã ‡§™‡§æ‡§§ ‡§¶‡•á‡§ñ‡§ø‡§Ø‡•ã' : '‡§Æ‡•á‡§∞‡•Ä ‡§´‡§∏‡§≤ ‡§Æ‡•á‡§Ç ‡§™‡•Ä‡§≤‡§æ‡§™‡§® ‡§π‡•à', 
                'Best crops for clay soil?', 
                language === 'ne' ? '‡§Ü‡§ú ‡§Æ‡•å‡§∏‡§Æ ‡§ï‡§∏‡•ç‡§§‡•ã ‡§õ?' : '‡§Ü‡§ú ‡§Æ‡•å‡§∏‡§Æ ‡§ï‡•à‡§∏‡§æ ‡§π‡•à?'
              ].map((suggestion, i) => (
                <Button
                  key={i}
                  variant="outline"
                  size="sm"
                  className="text-[10px] sm:text-xs h-7 sm:h-8 px-2 sm:px-3"
                  onClick={() => setInput(suggestion)}
                >
                  {suggestion}
                </Button>
              ))}
            </div>
          </div>
        )}

        <AnimatePresence>
          {messages.map((message) => (
            <motion.div
              key={message.id}
              initial={{ opacity: 0, y: 10 }}
              animate={{ opacity: 1, y: 0 }}
              className={`flex gap-2 sm:gap-3 ${message.role === 'user' ? 'flex-row-reverse' : ''}`}
            >
              <div className={`w-7 h-7 sm:w-8 sm:h-8 rounded-full flex items-center justify-center flex-shrink-0 ${
                message.role === 'user' 
                  ? 'bg-primary text-primary-foreground' 
                  : message.isOfflineResponse
                  ? 'bg-warning/20 text-warning'
                  : 'bg-accent/20 text-accent'
              }`}>
                {message.role === 'user' ? (
                  <User className="w-3.5 h-3.5 sm:w-4 sm:h-4" />
                ) : message.isOfflineResponse ? (
                  <CloudOff className="w-3.5 h-3.5 sm:w-4 sm:h-4" />
                ) : (
                  <Bot className="w-3.5 h-3.5 sm:w-4 sm:h-4" />
                )}
              </div>
              <Card className={`p-2.5 sm:p-3 max-w-[85%] sm:max-w-[80%] ${
                message.role === 'user' 
                  ? 'bg-primary text-primary-foreground' 
                  : message.isOfflineResponse
                  ? 'bg-warning/10 border-warning/20'
                  : 'bg-muted'
              }`}>
                {message.imageUrl && (
                  <img 
                    src={message.imageUrl} 
                    alt="Uploaded" 
                    className="rounded-lg mb-2 max-h-32 sm:max-h-48 w-auto"
                  />
                )}
                <p className="text-xs sm:text-sm whitespace-pre-wrap leading-relaxed">{message.content}</p>
                {message.role === 'assistant' && isProcessing && message.id === messages[messages.length - 1]?.id && !message.content && (
                  <div className="flex gap-1 py-2">
                    <span className="w-1.5 h-1.5 sm:w-2 sm:h-2 bg-current rounded-full animate-bounce" style={{ animationDelay: '0ms' }} />
                    <span className="w-1.5 h-1.5 sm:w-2 sm:h-2 bg-current rounded-full animate-bounce" style={{ animationDelay: '150ms' }} />
                    <span className="w-1.5 h-1.5 sm:w-2 sm:h-2 bg-current rounded-full animate-bounce" style={{ animationDelay: '300ms' }} />
                  </div>
                )}
                {/* Text-to-Speech button for assistant messages */}
                {message.role === 'assistant' && message.content && isTTSSupported && (
                  <div className="mt-2 pt-2 border-t border-border/50">
                    <Button
                      variant="ghost"
                      size="sm"
                      className={`h-6 sm:h-7 px-1.5 sm:px-2 gap-1 sm:gap-1.5 text-[10px] sm:text-xs ${
                        speakingMessageId === message.id 
                          ? 'text-primary bg-primary/10' 
                          : 'text-muted-foreground hover:text-foreground'
                      }`}
                      onClick={() => toggleSpeech(message.content, message.id)}
                    >
                      {speakingMessageId === message.id ? (
                        <>
                          <VolumeX className="w-3 h-3 sm:w-3.5 sm:h-3.5" />
                          {language === 'ne' ? '‡§∞‡•ã‡§ï‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç' : 'Stop'}
                        </>
                      ) : (
                        <>
                          <Volume2 className="w-3 h-3 sm:w-3.5 sm:h-3.5" />
                          {language === 'ne' ? '‡§∏‡•Å‡§®‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç' : 'Listen'}
                        </>
                      )}
                    </Button>
                  </div>
                )}
                
                {/* Treatment Video Cards for disease-related responses */}
                {message.role === 'assistant' && message.treatments && message.treatments.length > 0 && !isProcessing && (
                  <TreatmentVideoCards treatments={message.treatments} />
                )}
              </Card>
            </motion.div>
          ))}
        </AnimatePresence>
        
        {/* Processing indicator */}
        {(isAnalyzingDisease || isGettingRecommendations) && (
          <div className="flex items-center gap-2 text-xs sm:text-sm text-muted-foreground justify-center py-3 sm:py-4">
            <Loader2 className="w-3.5 h-3.5 sm:w-4 sm:h-4 animate-spin" />
            {isAnalyzingDisease 
              ? (language === 'ne' ? '‡§¨‡§æ‡§≤‡•Ä ‡§´‡•ã‡§ü‡•ã ‡§µ‡§ø‡§∂‡•ç‡§≤‡•á‡§∑‡§£ ‡§π‡•Å‡§Å‡§¶‡•à‡§õ...' : 'Analyzing crop image...')
              : (language === 'ne' ? '‡§∏‡§ø‡§´‡§æ‡§∞‡§ø‡§∏ ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§π‡•Å‡§Å‡§¶‡•à‡§õ...' : 'Getting recommendations...')}
          </div>
        )}
        
        <div ref={messagesEndRef} />
      </div>

      {/* Hidden disease image input */}
      <input
        type="file"
        ref={diseaseInputRef}
        onChange={handleDiseaseImageUpload}
        accept="image/*"
        capture="environment"
        className="hidden"
      />

      {/* Selected Image Preview */}
      {selectedImage && (
        <div className="px-4 pb-2">
          <div className="relative inline-block">
            <img 
              src={selectedImage} 
              alt="Selected" 
              className="h-20 rounded-lg border border-border"
            />
            <Button
              size="icon"
              variant="destructive"
              className="absolute -top-2 -right-2 w-6 h-6"
              onClick={() => setSelectedImage(null)}
            >
              <X className="w-3 h-3" />
            </Button>
          </div>
        </div>
      )}

      {/* Input */}
      <div className="p-3 sm:p-4 border-t border-border bg-muted/30 flex-shrink-0">
        {/* Quick action buttons when in chat */}
        {messages.length > 0 && (
          <div className="flex gap-1.5 sm:gap-2 mb-2 sm:mb-3 overflow-x-auto pb-1 sm:pb-2 scrollbar-hide">
            <Button
              variant="outline"
              size="sm"
              className="flex-shrink-0 gap-1 sm:gap-1.5 h-7 sm:h-8 text-[10px] sm:text-xs px-2 sm:px-3"
              onClick={handleGetCropRecommendations}
              disabled={isProcessing}
            >
              <Leaf className="w-3 h-3 sm:w-3.5 sm:h-3.5" />
              {language === 'ne' ? '‡§¨‡§æ‡§≤‡•Ä ‡§∏‡•Å‡§ù‡§æ‡§µ' : 'Crop Tips'}
            </Button>
            <Button
              variant="outline"
              size="sm"
              className="flex-shrink-0 gap-1 sm:gap-1.5 h-7 sm:h-8 text-[10px] sm:text-xs px-2 sm:px-3"
              onClick={() => diseaseInputRef.current?.click()}
              disabled={isProcessing}
            >
              <Bug className="w-3 h-3 sm:w-3.5 sm:h-3.5" />
              {language === 'ne' ? '‡§∞‡•ã‡§ó ‡§ú‡§æ‡§Å‡§ö' : 'Scan Disease'}
            </Button>
            
            {/* Voice Chat Button for OpenAI Realtime */}
            {isOnline && (
              <VoiceChatButton onMessage={handleRealtimeMessage} />
            )}
            
            {/* Settings Toggle */}
            <Button
              variant="outline"
              size="sm"
              className={`flex-shrink-0 gap-1 sm:gap-1.5 h-7 sm:h-8 text-[10px] sm:text-xs px-2 sm:px-3 ${showSettings ? 'bg-primary/10' : ''}`}
              onClick={() => setShowSettings(!showSettings)}
            >
              <Settings className="w-3 h-3 sm:w-3.5 sm:h-3.5" />
            </Button>
            
            <Button
              variant="outline"
              size="sm"
              className="flex-shrink-0 gap-1 sm:gap-1.5 ml-auto text-muted-foreground h-7 sm:h-8 text-[10px] sm:text-xs px-2 sm:px-3"
              onClick={clearChat}
            >
              <Trash2 className="w-3 h-3 sm:w-3.5 sm:h-3.5" />
              <span className="hidden sm:inline">{language === 'ne' ? '‡§ñ‡§æ‡§≤‡•Ä' : 'Clear'}</span>
            </Button>
          </div>
        )}
        
        {/* Settings Panel */}
        <AnimatePresence>
          {showSettings && (
            <motion.div
              initial={{ opacity: 0, height: 0 }}
              animate={{ opacity: 1, height: 'auto' }}
              exit={{ opacity: 0, height: 0 }}
              className="mb-2 sm:mb-3 p-2 sm:p-3 bg-muted/50 rounded-lg border border-border overflow-hidden"
            >
              <div className="flex items-center justify-between gap-2">
                <div className="flex items-center gap-2">
                  <Volume2 className="w-4 h-4 text-muted-foreground" />
                  <span className="text-xs sm:text-sm">
                    {language === 'ne' ? '‡§∏‡•ç‡§µ‡§§: ‡§Ü‡§µ‡§æ‡§ú ‡§™‡•ç‡§≤‡•á‡§¨‡•ç‡§Ø‡§æ‡§ï' : 'Auto-play voice'}
                  </span>
                </div>
                <Switch
                  checked={autoPlayTTS}
                  onCheckedChange={setAutoPlayTTS}
                  disabled={!isTTSSupported}
                />
              </div>
              <p className="text-[10px] sm:text-xs text-muted-foreground mt-1">
                {language === 'ne' 
                  ? 'AI ‡§ï‡•ã ‡§ú‡§µ‡§æ‡§´ ‡§∏‡•ç‡§µ‡§ö‡§æ‡§≤‡§ø‡§§ ‡§∞‡•Ç‡§™‡§Æ‡§æ ‡§¨‡•ã‡§≤‡§ø‡§®‡•á‡§õ'
                  : 'AI responses will be read aloud automatically'}
              </p>
            </motion.div>
          )}
        </AnimatePresence>

        {/* Voice Input Active Indicator */}
        <AnimatePresence>
          {isListening && (
            <motion.div
              initial={{ opacity: 0, y: 10 }}
              animate={{ opacity: 1, y: 0 }}
              exit={{ opacity: 0, y: 10 }}
              className="mb-2 sm:mb-3 p-3 bg-primary/10 border border-primary/30 rounded-lg"
            >
              <div className="flex items-center gap-2 mb-2">
                <div className="flex gap-1">
                  <span className="w-2 h-2 bg-primary rounded-full animate-bounce" style={{ animationDelay: '0ms' }} />
                  <span className="w-2 h-2 bg-primary rounded-full animate-bounce" style={{ animationDelay: '150ms' }} />
                  <span className="w-2 h-2 bg-primary rounded-full animate-bounce" style={{ animationDelay: '300ms' }} />
                </div>
                <span className="text-sm font-medium text-primary">
                  {language === 'ne' ? 'üé§ ‡§∏‡•Å‡§®‡§ø‡§∞‡§π‡•á‡§ï‡•ã ‡§õ...' : 'üé§ Listening...'}
                </span>
              </div>
              {transcript && (
                <p className="text-sm text-foreground bg-background/50 p-2 rounded border border-border">
                  {transcript}
                </p>
              )}
              <p className="text-xs text-muted-foreground mt-2">
                {language === 'ne' 
                  ? '‡§®‡•á‡§™‡§æ‡§≤‡•Ä‡§Æ‡§æ ‡§¨‡•ã‡§≤‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç‡•§ ‡§¨‡•ã‡§≤‡•ç‡§® ‡§∏‡§ï‡•á‡§™‡§õ‡§ø ‡§Æ‡§æ‡§á‡§ï ‡§¨‡§ü‡§® ‡§•‡§ø‡§ö‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç‡•§'
                  : 'Speak in your language. Tap the mic button when done.'}
              </p>
            </motion.div>
          )}
        </AnimatePresence>
        
        <div className="flex gap-1.5 sm:gap-2 items-end">
          <input
            type="file"
            ref={fileInputRef}
            onChange={handleImageUpload}
            accept="image/*"
            className="hidden"
          />
          <Button
            variant="outline"
            size="icon"
            onClick={() => fileInputRef.current?.click()}
            className="flex-shrink-0 h-9 w-9 sm:h-10 sm:w-10"
            disabled={isProcessing}
          >
            <Image className="w-4 h-4" />
          </Button>
          <Button
            variant={isListening ? "destructive" : "outline"}
            size="icon"
            onClick={toggleRecording}
            className={`flex-shrink-0 relative h-9 w-9 sm:h-10 sm:w-10 ${isListening ? 'ring-2 ring-destructive ring-offset-2' : ''}`}
            disabled={isProcessing}
            title={isVoiceSupported 
              ? (isListening 
                  ? (language === 'ne' ? '‡§∏‡•Å‡§®‡•ç‡§® ‡§∞‡•ã‡§ï‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç' : 'Stop listening') 
                  : (language === 'ne' ? 'üé§ ‡§¨‡•ã‡§≤‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç' : 'üé§ Speak')) 
              : (language === 'ne' ? '‡§Ü‡§µ‡§æ‡§ú ‡§∏‡§Æ‡§∞‡•ç‡§•‡§ø‡§§ ‡§õ‡•à‡§®' : 'Voice not supported')}
          >
            {isListening ? <MicOff className="w-4 h-4" /> : <Mic className="w-4 h-4" />}
            {isListening && (
              <span className="absolute -top-1 -right-1 w-2.5 h-2.5 sm:w-3 sm:h-3 bg-destructive rounded-full animate-ping" />
            )}
          </Button>
          <Textarea
            value={input}
            onChange={(e) => setInput(e.target.value)}
            onKeyPress={handleKeyPress}
            placeholder={isListening
              ? (language === 'ne' ? 'üé§ ‡§¨‡•ã‡§≤‡§ø‡§∞‡§π‡§®‡•Å‡§π‡•ã‡§∏‡•ç...' : 'üé§ Speaking...')
              : isOnline 
                ? (language === 'ne' ? '‡§®‡•á‡§™‡§æ‡§≤‡•Ä‡§Æ‡§æ ‡§ü‡§æ‡§á‡§™ ‡§ó‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç ‡§µ‡§æ üé§ ‡§•‡§ø‡§ö‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç...' : 'Type or tap üé§ to speak...')
                : (language === 'ne' ? '‡§Ö‡§´‡§≤‡§æ‡§á‡§® ‡§∏‡•Å‡§ù‡§æ‡§µ‡§ï‡•ã ‡§≤‡§æ‡§ó‡§ø ‡§ü‡§æ‡§á‡§™ ‡§ó‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç...' : 'Type for offline tips...')}
            className="min-h-[36px] sm:min-h-[44px] max-h-24 sm:max-h-32 resize-none text-sm"
            rows={1}
            disabled={isProcessing || isListening}
          />
          <Button
            onClick={sendMessage}
            disabled={isProcessing || (!input.trim() && !selectedImage)}
            className="flex-shrink-0 h-9 w-9 sm:h-10 sm:w-10"
            size="icon"
          >
            {isProcessing ? (
              <Loader2 className="w-4 h-4 animate-spin" />
            ) : (
              <Send className="w-4 h-4" />
            )}
          </Button>
        </div>
      </div>
    </div>
  );
}
